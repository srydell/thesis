% TODO: Write about method

The numberical simulations used in this thesis are presented in this chapter, starting with the Monte Carlo simulations, laying the background for the Worm algorithm. The Hoshen Kopelman algorithm, used for determining the location of the clusters in the graph is discussed, and an algorithm used for dividing the graph into boxes used in the box counting method is outlined. Finally, error estimation and code implementation is discussed.

\section{Monte Carlo Simulations}
\label{sec:MonteCarloSims}

A Monte Carlo simulation is a stochastic algorithm to get statistical results for a model system with many degrees of freedom. In Markov Chain Monte Carlo the idea is to use Markov Chains to propose the next step in the algorithm, i.e.\ the next proposed step is only dependent on the previous one. Using a well-chosen stationary probability distribution, together with ergodicity, the desired distribution can be sampled very efficiently.

\section{Ergodicity}
\label{sec:Ergodicity}

An ergodic system is one where time averages coincides with its ensemble averages. 

Intuitively, ergodicity is the assumption that a Markov chain starting from some state $S_a$ with a non-zero Boltzmann weight can reach any other state $S_b$ within a finite number of updates \cite{Zwanzig:nonequil_stat_mech}.

This is necessary to assume, since otherwise there could be a non zero contribution to the partition function not being sampled by the Markov chain.

\section{Detailed Balance}
\label{sec:DetailedBalance}

Generally, a Markov process can be described through the Master equation

\begin{equation}
    \frac{\mathrm d P_a}{\mathrm d t} = \sum_{a \neq b} \left ( P_b W_{ba} - P_a W_{ab} \right )
\end{equation}

\noindent where $P_a$ is the probability to find the system in the state a, and $W_{ab}$ is the transition rate from the state $a$ to $b$. This equation describes the equilibrating of $P_a$ into $P_a^{eq} \propto e^{-\beta E_a}$. The resulting equation is called detailed balance

\begin{equation}
    W_{ba} e^{\beta E_b} = W_{ab} e^{\beta E_a}
\end{equation}

This describes an equal rate of flow into the state $a$ as out of it.

Together with ergodicity, detailed balance ensures that the algorithm samples a desired target distribution, here the Boltzmann statistics \cite{Walter:IntroToMC}.

\section{Metropolis Algorithm}
\label{sec:MetropolisAlgorithm}

It is often very useful to factorize the transition rate according to

\begin{equation}
    W_{ab} = T_{ab} A_{ab}
\end{equation}

\noindent where $T_{ab}$ is a trial proposition probability and $A_{ab}$ is an acceptance probability. Letting $T_{ab} = T_{ba}, \ \forall a, \ b$ and choosing one of the acceptance probabilities $A_{ab}, \ A_{ba}$ to be equal to $1$, together with detailed balance, the Metropolis algorithm is realized \cite{Walter:IntroToMC}. The acceptance probability is therefore

\begin{equation}
    A_{ab} = \min \left \{ 1, \frac{P_b}{P_a} \right \} = \min \{ 1, e^{-\beta(E_b - E_a )} \}
\end{equation}


\section{Worm Algorithm}
\label{sec:WormAlgorithm}

The Worm algorithm operates on graph configurations instead of individual spins. This way, the algorithm can stay local and can avoid, to some extent, the so called critical slowdown that happens near transition points \cite{Prokofev:first_worm_algorithm}.

The algorithm still uses the Metropolis acceptance rates and therefore it fulfills detailed balance (see Sec. \ref{sec:DetailedBalance}).

The algorithm is divided into three parts. First a site and one of its neighbours are chosen at random on the lattice. The site and its neighbour $n$ is then connected with some acceptance probability. If the move was accepted, the `worm' is now at $n$ and chooses a neighbour to $n$ at random, creating a path onto the lattice. The algorithm finishes whenever the worm is back at its starting site, forming a loop. Now thermodynamic quantaties can be sampled and used for averages when sufficient data has been collected.

Intuitively, the `worm' part can be seen as a `magic marker' that can connect or remove the connection between two sites. This way the marker draws patterns onto a lattice that corresponds to a configuration, typically of the partition function. This paper is only concerned with whenever the marker reaches the same lattice site that it started on, forming loops, or clusters.

\section{Hoshen-Kopelman Algorithm}
\label{sec:HoshenKopelman}

To find the clusters a modified version of the Hoshen-Kopelman algorithm was used. A raster scan is used to label disjoint sets into groups with some canonical label \cite{Hoshen:HKAlgo}. It is a variant of the union-find algorithm and is most easily described through the associated functions, \textit{find} and \textit{union}. The union-find algorithm groups related sites together under a \textit{label}. Applying the find function on a site $i$ returns the canonical, often implemented as the smallest, label in the cluster that $i$ belongs to. Union uses find to ensure that two sites $i$ and $j$ are connected by setting the canonical label of $i$ to that of $j$ (or vice versa), essentially setting $i$ and $j$ under the same label. 

An example implementation would be to have a 2D graph without periodic boundary conditions of zeros and ones, where a site is occupied if it has a one associated with it, and unoccupied otherwise. A disjoint set here is a number of occupied sites neighbouring each other with unoccupied sites surrounding them. For simplicity the scan can start in the lower left corner, moving right and up, while search for neighbours left and down, ensuring that if a neighbouring site is occupied, it has been labeled before. This is done by following the steps outlined bellow.

Start by setting each site to a unique label, putting all sites in individual clusters. Go through the lattice until an occupied site $i$ is found. Search the neighbours below and to the left. If none of these neighbours are occupied, label $i$ have a unique label and move to the next site. If $i$ has one occupied neighbour it must have been labeled before, so $i$ inherits the neighbours label. Finally if both neighbours are occupied, site $i$ must be connecting a cluster and a union is performed on the neighbours to join their labels. A final pass through the lattice using the find function ensures that all sites have their canonical label.

In this paper an occupied site corresponds to a site with connections to the neighbouring sites (in the 2D example above, each site could have four such connections). In the original paper by Hoshen and Kopelman \cite{Hoshen:HKAlgo} the labels for the sites who did not originally carry the canonical label, were set to a negative integer, symbolizing that they were aliases. A positive value was used at the canonical label, showing the number of sites in that cluster. This was not used in this project since the number of links in a cluster is not necessarily equal to the number of sites.

\section{Graph Dividing Algorithm}
\label{sec:GraphDivisonAlgorithm}


In order to calculate the box dimension the lattice is divided into boxes of decreasing size (see Sec. \ref{sec:boxdimension}). For this a new algorithm was written exploiting that all graphs in this thesis had a linear system size of $2^{n}$, where $n$ is some integer. The algorithm could easily be generalized to $x^n$ or using other configurations by a well-chosen stopping length $l_0$. What follows is a brief overview of the algorithm and for intuition, one step in the recursion can be seen in Fig. (\ref{fig:graphdividingalgo}).

For brevity some abbreviations are first introduced.

\begin{equation*}
    \begin{aligned}
        d =& \ \text{dimension} &\quad l_i =& \ \text{side length of the current box}\\
%
        l_0 =& \ \text{side length of the} &\quad e_i^j =& \ \text{vector of length } l_i / 2 \\
%
             & \ \text{smallest box allowed} & & \text{ in the }j\text{'th direction} \\
%
        \text{perm}(v) =& \ \text{All permutations of } v &\quad s_i =& \ \text{starting site of the current box}
    \end{aligned}
\end{equation*}

The graph dividing algorithm is defined by the following steps:

\begin{enumerate}
    \item If $l_i \geq l_0$, go to 2, else stop.
%
    \item Save all sites in the current box, starting from $s_i$ going $l_i$ in $d$ directions.
%
    \item Find all starting points for new boxes.
%
    \begin{enumerate}[label=(\roman*)]
%
        \item Form the matrix $E = (e_i^0, e_i^1, \  \ldots, e_i^d)^T$
%
        \item For all vectors $v_k$ in perm$(0, 0, \ \ldots , 0)$, perm$(1, 0, \ \ldots , 0)$, \\ \ldots, perm$(1, 1, \ \ldots , 1)$, create the new start $s_k$ as $$s_k = v_k E$$
%
    \end{enumerate}
%
    \item For each start $s_k$:
    \begin{enumerate}[label=(\roman*)]
        \item $s_i = s_k$, $l_i = l_i / 2$
        \item Go to 1.
    \end{enumerate}
%
\end{enumerate}


\begin{figure}[h!]
    \centering
        \includegraphics[width=0.7\textwidth]{figures/graphDividing.pdf}
    \caption{One step in the graph dividing algorithm where $l_i = 4$. $e^0_i$ and $e^1_i$ are drawn from site $s_i$. Summed permutations of $\{e^0_i, e^1_i\}$ give the starts for the next boxes. The next iteration of boxes are shown via the dividing dotted lines.}
    \label{fig:graphdividingalgo}
\end{figure}

This algorithm can be written to perform in linear time, as can be seen in Fig. (\ref{fig:bench_graphdiv}). 

\begin{figure}[h!]
    \centering
        \includegraphics[width=0.7\textwidth]{figures/bench_graph_div.pdf}
    \caption{Loglog plot of a benchmark of the graph dividing algorithm. The y-axis show the time taken to perform one full graph divide normalized with the smallest time value.}
    \label{fig:bench_graphdiv}
\end{figure}

%TODO: Newpage
\newpage


\section{Error Estimation}
\label{sec:ErrorEst}

In this thesis a number of error estimation techniques were used to control the statistical uncertainty of the results. In this section these techniques will be reviewed.

\subsection{Monte Carlo Error Estimation}
\label{subsec:MonteCarloErrorEst}

Given a Monte Carlo simulation where polling of some quantity $A$ has been done $N$ times an estimation of the expectation value of $A$ is

\begin{equation}
    \bar A = \frac{1}{N} \sum_{i = 1}^{N} A_i
\end{equation}

\noindent where each sampling was labeled $A_i$. To show that this is an unbiased estimator the expectation value of the difference between the estimation and the real value $\langle A \rangle$ is used.

\begin{align}
    \langle \bar A - \langle A \rangle \rangle &= \langle \bar A \rangle - \langle A \rangle \\
%
    &= \left \langle \frac{1}{N} \sum_{i = 1}^{N} A_i \right \rangle - \langle A \rangle \\
%
    &= \langle A \rangle - \langle A \rangle = 0
    \label{eq:unbiasedEst}
\end{align}

\noindent where the fact that $A_i$ are random samples from the distribution of $A$ was used in Eq. (\ref{eq:unbiasedEst}).

The standard deviation of this estimate can be calculated as

\begin{align}
    \sigma_{\bar A}^{2} &= V\left( \bar A - \langle A \rangle \right ) \\
%
    &= \{ \langle A \rangle \ \text{is a constant} \Rightarrow V(\langle A \rangle) = 0 \} \\
%
    &= V \left ( \frac{1}{N} \sum_{i = 1}^{N} A_i \right ) \\
%
    &= \{ \text{Monte Carlo simulations give independent samples} \} \\
%
    &= \frac{1}{N^2} \sum_{i = 1}^{N} V(A_i) \\
%
    &= \frac{\sigma_{A}^2}{N}
\end{align}

\noindent or

\begin{equation}
    \sigma_{\bar A} = \frac{\sigma_A}{\sqrt{N}}
\end{equation}

\noindent so the standard error in this estimation decreases as $N^{-1/2}$.

\subsection{Bootstrap Error Analysis}
\label{subsec:Bootstrap}

Bootstrap is a resampling method to examine a probability distribution. In this thesis it was used to estimate the error propagation of parameters in curve fitting.

Given a set $\bm x$ of $N$ measurements from an unknown distribution $\hat \phi$, some statistical calculation of interest can be done as $\theta = s(\bm x)$. A resampling $\bm x_0$ of $\bm x$ comprised of $N$ random measurements from $\bm x$ (where one measurement can be included several times), can then be used to calculate $\theta^*_0 = s(\bm x_0)$. Repeating this $N_B$ times gives an estimate $\theta^* = (\theta^*_0, \theta^*_1, ..., \theta^*_{N_B})$ of the distribution $\hat \theta$. Assuming $N_B$ is large then, by the central limit theorem, $\hat \theta$ is a normal distribution with some standard deviation $\sigma_\theta$ that can be used as an error estimation for $\theta$.

\section{Optimization}
\label{sec:Optimization}

All simulation code were implemented by the author. Hence, a large part of this project was spent optimizing the simulations. To fascilitate this process, the Google C++ framework \textit{benchmark} was used for measuring and comparing running times of different algorithms. Only the C++ code was optimized in this way since the prototypes written in Python were not concerned with computational speed. What follows is a summation of the biggest optimizations that were achieved during this project.

\subsection{Lattice implementation - Squashing the Graph}
\label{subsec:LatticeImpl}

During most of the calculations a sweep through the entire lattice was necessary. The computational time taken by such a sweep is heavily affected by the implementation of the lattice data structure.

The first implementation used an array of arrays to represent the lattice. This has the advantage of a similar interface to mathematical matrices with rows and columns. However, it is much slower than a single array, or a squashed graph, most likely due to cache misses\cite{Hanlon:CacheMisses}. Figure (\ref{fig:bench_latticeimpl}) shows a comparison between the time it takes to do one full sweep in the two implementations.

Furthermore, this simplifies the generalization to lattices of different dimensions since the need to allocate a set number of arrays in each array disappears. It also makes it easier to reuse the same algorithm for lattices of different dimensions.

The mapping used between the array index and the Euclidean space is

\begin{equation}
    n = x + y L + z L^2 + ...
\end{equation}

\noindent where $L$ is the linear system size.

\begin{figure}[h!]
    \centering
        \includegraphics[width=0.8\textwidth]{figures/bench_latticeimpl.pdf}
    \caption{Plot of a sweep benchmark of two different lattice implementations. The red dots labeled $\bar t_{multi}$ is an array of arrays, while the green dots labeled $\bar t_{single}$ is a single array. The y-axis show the time taken to perform one full graph divide normalized against the maximum of the smallest time value for the two implementations.}
    \label{fig:bench_latticeimpl}
\end{figure}

\subsection{Saving Warmed Up Graphs}
\label{subsec:SavingWarmedUpGraphs}

In order to produce valid results from a simulation, a physical system must be sampled. Since there is no reliable way to guess a physical state of a system at the start of a simulation, each system must be `warmed up' to produce valid results. One way of doing this is to iteratively update the system until measurements of the quantity of intereset is sufficiently stable. This is then assumed to be a physical state. A representation of the graph is stored on disk to be used as a starting point for following simulations. This greatly helped with performance as it decreased the simulation times.

In this thesis, the graph was saved to a text file, that could then be parsed with Python to plot the data, or C++ to simulate the system further. The drawback of this solution is the need for a self-written parser. Since the simulation and plotting were done in two different programming languages, the better solution would be a combined interface such as a database.

\section{Testing}
\label{sec:Testing}

Testing is an essential part of writing a simulation. The correctness of the code ensures that the physical model is aptly described. To facilitate the development, a number of coding practices were applied, such as unit testing (Sec. \ref{sec:UnitTesting}) and regression testing (Section \ref{sec:RegressionTesting}). The tests for the prototypes were written in the Python standard library utility \textit{unittest}, and those for the main simulation used the C++ framework \textit{Catch2}.

\subsection{Unit Testing}
\label{sec:UnitTesting}

Unit testing refers to the practice of isolating a `unit' of code and testing its correctness. A unit can be any small piece of code with an expected behaviour. This was done by manually calculating the expected output of some code, given some input, and ensuring that the piece of code produced an equivalent result. The parts of the simulation using a pseudorandom number generator were tested by randomly selecting a set of seeds on which the tests were run upon. The correctness is then assumed from this subset of possible inputs. Combining multiple units into one test is called integration testing. This assumes that each unit is correct by itself, and it was used to more closely ressemble the actual simulation.

\subsection{Regression Testing}
\label{sec:RegressionTesting}

Rerunning the relevant tests in a continuous manner after each update is called regression testing. This ensures that, however many unintended consequences were introduced during the update, the expected behaviour of the program is still intact. This was done by writing a `hook' such that, whenever a piece of code were recompiled, the relevant tests were subsequently compiled and run. With sufficient tests in place, the correctness of the code was verified after any modification was done.


